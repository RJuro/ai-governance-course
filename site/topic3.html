<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Topic 3: AI as Normal Technology</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;1,400&family=DM+Sans:wght@400;500;600&family=Caveat:wght@500&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-dark: #2A2320;
      --bg-warm: #342D29;
      --bg-card: #3D3632;
      --coral: #E8734A;
      --coral-light: #F5A17A;
      --cream: #F5F0EB;
      --text-light: #E8E4E0;
      --text-muted: #9A938D;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'DM Sans', sans-serif;
      background: var(--bg-dark);
      color: var(--text-light);
      line-height: 1.7;
      font-size: 16px;
    }
    body::before {
      content: '';
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      opacity: 0.03;
      pointer-events: none;
      background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 256 256' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noise'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noise)'/%3E%3C/svg%3E");
    }
    .container { max-width: 900px; margin: 0 auto; padding: 3rem 2rem; }
    .back-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--coral);
      text-decoration: none;
      font-size: 0.9rem;
      margin-bottom: 2rem;
    }
    .back-link:hover { gap: 0.75rem; }
    .topic-header {
      display: flex;
      justify-content: space-between;
      align-items: flex-start;
      margin-bottom: 2rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid rgba(255,255,255,0.08);
    }
    .topic-header h1 {
      font-family: 'Cormorant Garamond', serif;
      font-size: clamp(2rem, 4vw, 2.75rem);
      font-weight: 400;
      color: var(--cream);
      line-height: 1.2;
    }
    .topic-num {
      font-family: 'Cormorant Garamond', serif;
      font-size: 4rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.25;
      line-height: 1;
    }
    h2 {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.5rem;
      font-weight: 400;
      color: var(--cream);
      margin: 2.5rem 0 1rem;
    }
    h3 {
      font-size: 0.95rem;
      font-weight: 600;
      color: var(--cream);
      margin: 1.5rem 0 0.75rem;
    }
    p { color: var(--text-muted); margin-bottom: 0.75rem; }
    strong { color: var(--text-light); }
    a { color: var(--coral-light); }
    a:hover { text-decoration: none; }
    ul, ol { color: var(--text-muted); margin: 1rem 0; padding-left: 1.25rem; }
    li { margin-bottom: 0.5rem; }
    .reading-box {
      background: var(--bg-warm);
      border-left: 4px solid var(--coral);
      border-radius: 4px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .reading-box h4 {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.35rem;
      color: var(--cream);
      margin-bottom: 0.75rem;
    }
    .reading-box p { margin: 0.25rem 0; font-size: 0.95rem; }
    .questions ol { counter-reset: q; list-style: none; padding: 0; }
    .questions li {
      counter-increment: q;
      padding: 0.75rem 0 0.75rem 2.5rem;
      position: relative;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    .questions li::before {
      content: counter(q);
      position: absolute;
      left: 0;
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.6;
    }
    .angles ol { counter-reset: a; list-style: none; padding: 0; }
    .angles li {
      counter-increment: a;
      padding: 0.75rem 0;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    .note-box {
      background: var(--bg-warm);
      padding: 1rem;
      border-radius: 6px;
      margin-top: 2rem;
    }
    footer {
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 1px solid rgba(255,255,255,0.08);
    }
    @media (max-width: 600px) {
      .topic-header { flex-direction: column-reverse; gap: 1rem; }
      .topic-num { font-size: 3rem; }
    }
  </style>
</head>
<body>
  <div class="container">
    <a href="index.html" class="back-link">← Back to overview</a>

    <header class="topic-header">
      <h1>AI as Normal Technology</h1>
      <span class="topic-num">03</span>
    </header>

    <p>This topic challenges the dominant narratives of AI exceptionalism. Narayanan and Kapoor, authors of the influential book <em>AI Snake Oil</em>, argue that AI should be understood as a "normal" general-purpose technology like electricity or the internet. Transformative, yes, but not an autonomous superintelligent entity requiring radically new governance approaches. They argue impacts will unfold gradually over decades and existing institutions are sufficient to maintain human control.</p>

    <p><strong>Why this matters for Danish AI policy:</strong> If AI is "normal," Denmark can rely more heavily on adapting existing regulatory frameworks. If AI is exceptional, entirely new institutions may be needed. This framing question underlies all AI policy decisions.</p>

    <h2>Required Reading</h2>
    <div class="reading-box">
      <h4>AI as Normal Technology</h4>
      <p><strong>Authors:</strong> Arvind Narayanan &amp; Sayash Kapoor</p>
      <p><strong>Publication:</strong> Knight First Amendment Institute at Columbia University, April 2025</p>
      <p><strong>Length:</strong> Full essay ~15,000–18,000 words; <strong>assign Parts I and IV only (~6,500 words)</strong></p>
      <p><strong>URL:</strong> <a href="https://knightcolumbia.org/content/ai-as-normal-technology">knightcolumbia.org/content/ai-as-normal-technology</a></p>
      <p><strong>Alternative:</strong> <a href="https://www.normaltech.ai/">normaltech.ai</a> (Substack with newsletter)</p>
    </div>

    <h3>Sections to Focus On</h3>
    <ul>
      <li><strong>Part I: "AI is normal" thesis.</strong> The core argument framed as description, prediction, and prescription.</li>
      <li><strong>"Ladder of Generality" (Figure 2).</strong> Key conceptual framework.</li>
      <li><strong>"Capability-reliability gap."</strong> Why AI capabilities don't automatically translate to reliable deployment.</li>
      <li><strong>Part IV: Policy implications.</strong> What "normal technology" means for governance.</li>
    </ul>

    <h3>Author Credentials</h3>
    <p><strong>Arvind Narayanan</strong> is Professor of Computer Science at Princeton and Director of the Center for Information Technology Policy. Named in TIME's 100 Most Influential People in AI, he received the Presidential Early Career Award.</p>
    <p><strong>Sayash Kapoor</strong> is a PhD candidate at Princeton and Senior Fellow at Mozilla.</p>
    <p>Both co-authored <em>AI Snake Oil</em> (2024), a widely-cited critique of AI hype.</p>

    <h2>Supplementary Materials</h2>

    <h3>Podcasts &amp; Videos</h3>
    <ul>
      <li><a href="https://open.spotify.com/episode/42R3RLEA2sNPLVIu55NV5b">NYT Hard Fork podcast</a> (April 2025). "Is A.I. a 'Normal' Technology?" Interview with Narayanan.</li>
      <li><a href="https://open.spotify.com/episode/5fNu11wSgg0WTkFg1LM0zH">AI Agents: Substance or Snake Oil</a>. Spotify episode with Narayanan.</li>
      <li><a href="https://podcasts.apple.com/us/podcast/497-spotting-the-difference-between-ai-innovation-and/id1566956045?i=1000683179750">Spotting the Difference Between AI Innovation and AI Snake Oil</a>. Apple Podcasts.</li>
    </ul>

    <h3>Debate Context</h3>
    <ul>
      <li>Both authors debated Daniel Kokotajlo of the AI 2027 project, representing opposing views on AI timelines.</li>
      <li>This reading pairs with <strong>Topic 4 (Aschenbrenner)</strong> as opposing worldviews.</li>
    </ul>

    <h3>Additional Context</h3>
    <ul>
      <li><em>AI Snake Oil</em> (book). Deeper background on their arguments.</li>
      <li>EU AI Act. Example of treating AI as "normal" (sector-specific, risk-based).</li>
      <li>Historical technology transitions. Electricity, internet, prior GPTs.</li>
    </ul>

    <h2>Guiding Questions</h2>
    <div class="questions">
      <ol>
        <li><strong>The normality claim:</strong> Narayanan and Kapoor argue AI is "normal." What exactly do they mean by this? Is it a description of current AI, a prediction about future AI, or a prescription for how we should think about AI?</li>
        <li><strong>Capability-reliability gap:</strong> The authors argue AI capabilities don't automatically translate to reliable real-world deployment. What are examples of this gap? How should Danish policy account for it?</li>
        <li><strong>Institutional sufficiency:</strong> They claim existing institutions are sufficient to govern AI. Is this true for Denmark? What existing Danish/EU institutions are most relevant? What gaps, if any, exist?</li>
        <li><strong>The timeline question:</strong> If AI impacts unfold over decades rather than years, how should this change Danish policy priorities? What's the cost of preparing for rapid change that doesn't materialize?</li>
        <li><strong>Critique:</strong> Some argue this view underestimates discontinuous progress. How should policymakers weigh "normal technology" arguments against more alarmist perspectives like Aschenbrenner's (Topic 4)?</li>
      </ol>
    </div>

    <h2>Presentation Angle Ideas</h2>
    <div class="angles">
      <ol>
        <li><strong>"Adapt, Don't Reinvent":</strong> Argue that Denmark should focus on adapting existing regulatory frameworks (labor law, data protection, sector-specific regulation) rather than creating new AI-specific institutions.</li>
        <li><strong>"The Capability-Reliability Gap in Danish Context":</strong> Use the authors' framework to analyze specific Danish use cases. Where is AI being deployed despite reliability concerns? What policies address this?</li>
        <li><strong>"Hedging Between Worldviews":</strong> Acknowledge deep uncertainty about AI trajectories. Propose a Danish policy approach that's robust whether AI proves "normal" or "exceptional."</li>
        <li><strong>"Lessons from Past Technologies":</strong> Use historical analogies (electricity, internet, previous automation waves) to inform Danish AI policy. What did Denmark get right and wrong in past technology transitions?</li>
      </ol>
    </div>

    <p class="note-box"><strong>Note:</strong> This reading presents the <em>opposite</em> worldview from Topic 4 (Aschenbrenner). Together they represent the key debate in AI governance: Is AI a normal technology requiring incremental policy adaptation, or an exceptional technology requiring urgent, transformative governance?</p>

    <footer>
      <a href="index.html" class="back-link">← Back to overview</a>
    </footer>
  </div>
</body>
</html>
