<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Topic 1: AI Risk Frameworks</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,600;1,400&family=Source+Sans+3:wght@400;500;600&family=Caveat:wght@500&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-dark: #2C2421;
      --bg-warm: #362E2A;
      --bg-card: #3D3531;
      --cream: #FAF7F2;
      --cream-dark: #EDE8E0;
      --coral: #E07850;
      --coral-light: #F0A080;
      --text-light: #F0EBE5;
      --text-light-muted: #A89B91;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'Source Sans 3', sans-serif;
      background: var(--bg-dark);
      color: var(--text-light);
      line-height: 1.7;
      font-size: 16px;
    }
    body::before {
      content: '';
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      pointer-events: none;
      z-index: 0;
      background-image: radial-gradient(circle, rgba(255,255,255,0.08) 1px, transparent 1px);
      background-size: 24px 24px;
    }
    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 3rem 2rem;
      position: relative;
      z-index: 1;
    }
    .back-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--coral);
      text-decoration: none;
      font-size: 0.9rem;
      font-weight: 500;
      margin-bottom: 2rem;
      transition: gap 0.2s ease;
    }
    .back-link:hover { gap: 0.75rem; }
    .topic-header {
      display: flex;
      justify-content: space-between;
      align-items: flex-start;
      margin-bottom: 2rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid rgba(255,255,255,0.08);
    }
    .topic-header h1 {
      font-family: 'Playfair Display', serif;
      font-size: clamp(2rem, 4vw, 2.75rem);
      font-weight: 400;
      color: var(--cream);
      line-height: 1.2;
    }
    .topic-num {
      font-family: 'Playfair Display', serif;
      font-size: 4rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.25;
      line-height: 1;
    }
    h2 {
      font-family: 'Playfair Display', serif;
      font-size: 1.5rem;
      font-weight: 400;
      color: var(--cream);
      margin: 2.5rem 0 1rem;
    }
    h3 {
      font-size: 0.95rem;
      font-weight: 600;
      color: var(--cream);
      margin: 1.5rem 0 0.75rem;
    }
    p { color: var(--text-light-muted); margin-bottom: 0.75rem; }
    strong { color: var(--text-light); }
    a { color: var(--coral-light); }
    a:hover { text-decoration: none; }
    ul, ol { color: var(--text-light-muted); margin: 1rem 0; padding-left: 1.25rem; }
    li { margin-bottom: 0.5rem; }
    .reading-box {
      background: var(--bg-warm);
      border-left: 4px solid var(--coral);
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .reading-box h4 {
      font-family: 'Playfair Display', serif;
      font-size: 1.35rem;
      color: var(--cream);
      margin-bottom: 0.75rem;
    }
    .reading-box p { margin: 0.25rem 0; font-size: 0.95rem; }
    .questions ol { counter-reset: q; list-style: none; padding: 0; }
    .questions li {
      counter-increment: q;
      padding: 0.75rem 0 0.75rem 2.5rem;
      position: relative;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    .questions li::before {
      content: counter(q);
      position: absolute;
      left: 0;
      font-family: 'Playfair Display', serif;
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.6;
    }
    .angles ol { counter-reset: a; list-style: none; padding: 0; }
    .angles li {
      counter-increment: a;
      padding: 0.75rem 0;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    .note-box {
      background: var(--bg-warm);
      padding: 1rem 1.5rem;
      margin-top: 2rem;
    }
    footer {
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 1px solid rgba(255,255,255,0.08);
    }
    @media (max-width: 600px) {
      .topic-header { flex-direction: column-reverse; gap: 1rem; }
      .topic-num { font-size: 3rem; }
    }
  </style>
</head>
<body>
  <div class="container">
    <a href="index.html" class="back-link">← Back to overview</a>

    <header class="topic-header">
      <h1>AI Risk Frameworks</h1>
      <span class="topic-num">01</span>
    </header>

    <p>This topic examines how humanity should approach the risks posed by increasingly powerful AI systems. Dario Amodei's essay argues that we are entering a "technological adolescence": a critical period where powerful AI could arrive within years, presenting existential risks that require a pragmatic "battle plan" combining technical safety research, transparency legislation, and international coordination.</p>

    <p><strong>Why this matters for Danish AI policy:</strong> Denmark must decide how to position itself in international AI safety governance. Should it prioritize EU coordination, transatlantic cooperation, or develop independent safety frameworks?</p>

    <h2>Required Reading</h2>
    <div class="reading-box">
      <h4>The Adolescence of Technology</h4>
      <p><strong>Author:</strong> Dario Amodei</p>
      <p><strong>Publication:</strong> Personal blog, January 2026</p>
      <p><strong>Length:</strong> ~7,500 words (selected sections)</p>
      <p><strong>URL:</strong> <a href="https://www.darioamodei.com/essay/the-adolescence-of-technology">darioamodei.com/essay/the-adolescence-of-technology</a></p>
    </div>

    <h3>Sections to Focus On</h3>
    <ul>
      <li><strong>Introduction through "Powerful AI" definition</strong> (~2,500–3,000 words)</li>
      <li><strong>"Player Piano" section</strong> (~3,500–4,000 words)</li>
      <li><strong>"Humanity's test" conclusion</strong> (~1,000–1,500 words)</li>
    </ul>

    <h3>Author</h3>
    <p>CEO and co-founder of Anthropic. PhD in physics from Princeton. Former VP of Research at OpenAI. Pioneer of AI scaling laws research.</p>

    <h2>Supplementary Materials</h2>
    <ul>
      <li><a href="https://podcasts.apple.com/py/podcast/on-the-adolescence-of-technology-by-zvi/id1698192712?i=1000747464714">Zvi Mowshowitz analysis</a> (54 min podcast). Also on <a href="https://thezvi.substack.com/p/on-the-adolescence-of-technology">Substack</a>.</li>
      <li>"Machines of Loving Grace" (Amodei, 2024). Earlier essay on AI benefits.</li>
      <li>Anthropic's Constitutional AI paper. Technical safety background.</li>
    </ul>

    <h2>Guiding Questions</h2>
    <div class="questions">
      <ol>
        <li><strong>Risk assessment:</strong> Amodei identifies five categories of existential risk. Which are most relevant for Denmark? Are there Denmark-specific risks he doesn't address?</li>
        <li><strong>Governance mechanisms:</strong> The essay proposes Constitutional AI, interpretability research, and transparency legislation. How well do these map to EU frameworks like the AI Act?</li>
        <li><strong>Timeline uncertainty:</strong> Amodei suggests powerful AI could arrive within "one to two years." How should Danish policymakers plan under such uncertainty?</li>
        <li><strong>Small state strategy:</strong> Denmark cannot unilaterally shape AI development. What role can a small democracy play in international AI safety governance?</li>
        <li><strong>Critique:</strong> Some argue Amodei's framing overstates near-term risks to justify Anthropic's business model. How should policymakers weigh arguments from industry insiders?</li>
      </ol>
    </div>

    <h2>Presentation Angle Ideas</h2>
    <div class="angles">
      <ol>
        <li><strong>"Denmark as AI Safety Laboratory":</strong> Denmark should position itself as a testing ground for AI safety governance, leveraging strong institutions and small scale to pilot approaches.</li>
        <li><strong>"Beyond Doom and Optimism":</strong> Evaluate Amodei's claim that both "naive optimism" and "paralyzed doomerism" are failures. What's pragmatic Danish policy?</li>
        <li><strong>"The Timeline Question":</strong> Should Denmark's policy assume rapid AI progress or slower progress?</li>
        <li><strong>"Coordinating with the EU":</strong> How can Denmark work within EU structures while engaging with US-led AI safety initiatives?</li>
      </ol>
    </div>

    <footer>
      <a href="index.html" class="back-link">← Back to overview</a>
    </footer>
  </div>
</body>
</html>
