<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Topic 7: AI and Democracy</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;1,400&family=DM+Sans:wght@400;500;600&family=Caveat:wght@500&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-dark: #2A2320;
      --bg-warm: #342D29;
      --bg-card: #3D3632;
      --coral: #E8734A;
      --coral-light: #F5A17A;
      --cream: #F5F0EB;
      --text-light: #E8E4E0;
      --text-muted: #9A938D;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'DM Sans', sans-serif;
      background: var(--bg-dark);
      color: var(--text-light);
      line-height: 1.7;
      font-size: 16px;
    }
    body::before {
      content: '';
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      opacity: 0.03;
      pointer-events: none;
      background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 256 256' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noise'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noise)'/%3E%3C/svg%3E");
    }
    .container { max-width: 900px; margin: 0 auto; padding: 3rem 2rem; }
    .back-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--coral);
      text-decoration: none;
      font-size: 0.9rem;
      margin-bottom: 2rem;
    }
    .back-link:hover { gap: 0.75rem; }
    .topic-header {
      display: flex;
      justify-content: space-between;
      align-items: flex-start;
      margin-bottom: 2rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid rgba(255,255,255,0.08);
    }
    .topic-header h1 {
      font-family: 'Cormorant Garamond', serif;
      font-size: clamp(2rem, 4vw, 2.75rem);
      font-weight: 400;
      color: var(--cream);
      line-height: 1.2;
    }
    .topic-num {
      font-family: 'Cormorant Garamond', serif;
      font-size: 4rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.25;
      line-height: 1;
    }
    h2 {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.5rem;
      font-weight: 400;
      color: var(--cream);
      margin: 2.5rem 0 1rem;
    }
    h3 {
      font-size: 0.95rem;
      font-weight: 600;
      color: var(--cream);
      margin: 1.5rem 0 0.75rem;
    }
    p { color: var(--text-muted); margin-bottom: 0.75rem; }
    strong { color: var(--text-light); }
    a { color: var(--coral-light); }
    a:hover { text-decoration: none; }
    ul, ol { color: var(--text-muted); margin: 1rem 0; padding-left: 1.25rem; }
    li { margin-bottom: 0.5rem; }
    .reading-box {
      background: var(--bg-warm);
      border-left: 4px solid var(--coral);
      border-radius: 4px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .reading-box h4 {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.35rem;
      color: var(--cream);
      margin-bottom: 0.75rem;
    }
    .reading-box p { margin: 0.25rem 0; font-size: 0.95rem; }
    .questions ol { counter-reset: q; list-style: none; padding: 0; }
    .questions li {
      counter-increment: q;
      padding: 0.75rem 0 0.75rem 2.5rem;
      position: relative;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    .questions li::before {
      content: counter(q);
      position: absolute;
      left: 0;
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.6;
    }
    .angles ol { counter-reset: a; list-style: none; padding: 0; }
    .angles li {
      counter-increment: a;
      padding: 0.75rem 0;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    footer {
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 1px solid rgba(255,255,255,0.08);
    }
    @media (max-width: 600px) {
      .topic-header { flex-direction: column-reverse; gap: 1rem; }
      .topic-num { font-size: 3rem; }
    }
  </style>
</head>
<body>
  <div class="container">
    <a href="index.html" class="back-link">← Back to overview</a>

    <header class="topic-header">
      <h1>AI and Democracy</h1>
      <span class="topic-num">07</span>
    </header>

    <p>This topic examines how AI affects democratic processes and information ecosystems. Csernatoni argues that AI-generated content enables manipulation of information and disruption of electoral processes, but the collision between rapid AI advancement and eroding democratic safeguards requires comprehensive response combining technical solutions (watermarking, content provenance), governance tools, and digital literacy.</p>

    <p><strong>Why this matters for Danish AI policy:</strong> Denmark has strong democratic institutions but is not immune to AI-enabled disinformation. The Digital Democracy Initiative (2023–2026) and proposed deepfake legislation show Denmark is actively addressing these issues. What more should be done?</p>

    <h2>Required Reading</h2>
    <div class="reading-box">
      <h4>Can Democracy Survive the Disruptive Power of AI?</h4>
      <p><strong>Author:</strong> Raluca Csernatoni</p>
      <p><strong>Publication:</strong> Carnegie Europe, December 2024</p>
      <p><strong>Length:</strong> ~4,000–4,500 words</p>
      <p><strong>URL:</strong> <a href="https://carnegieendowment.org/europe/research/2024/12/can-democracy-survive-the-disruptive-power-of-ai">carnegieendowment.org/europe/research/2024/12/can-democracy-survive-the-disruptive-power-of-ai</a></p>
    </div>

    <h3>Author Credentials</h3>
    <p>Raluca Csernatoni is a Fellow at Carnegie Europe specializing in European security and emerging technologies. She is Professor at the Brussels School of Governance (VUB) and Senior Research Expert on the EU Cyber Direct project. She holds a PhD in International Relations from Central European University and has published in <em>Minds and Machines</em>, <em>European Security</em>, and <em>Geopolitics</em>.</p>

    <h2>Supplementary Materials</h2>

    <h3>Podcasts &amp; Videos</h3>
    <ul>
      <li><a href="https://www.brookings.edu/articles/how-do-artificial-intelligence-and-disinformation-impact-elections/">Brookings: How do AI and disinformation impact elections?</a>. Analysis with Darrell West and Nicol Turner Lee.</li>
      <li><a href="https://podcasts.apple.com/us/podcast/democracy-in-question/id1761380906">Democracy in Question podcast</a> (Brookings). Biweekly episodes on democracy and technology. Available on <a href="https://open.spotify.com/show/2CoxRRiyYXtJlOREgoD3vN">Spotify</a>.</li>
    </ul>

    <h3>Alternative Perspectives</h3>
    <ul>
      <li>Munich Security Conference: "AI-pocalypse Now?" (September 2024, ~5,500 words). Evidence-based finding that AI disinformation had <em>negligible actual impact</em> in 2024's "super election year"; covers EU, UK, France, Slovakia, Taiwan, US, India.</li>
      <li>AlgorithmWatch: "10 Questions About AI and Elections" (May 2024, ~2,500 words). Contrarian perspective arguing deepfake hype is overblown; real threat is recommendation algorithms and platform consolidation.</li>
      <li>Alan Turing Institute/CETaS: "AI-Enabled Influence Operations" (September 2024, ~6,500 words). Empirical study finding only 16 viral AI disinformation cases during UK election.</li>
    </ul>

    <h3>Danish Context</h3>
    <ul>
      <li><strong>Digital Democracy Initiative</strong> (2023–2026, 200m DKK). Supports civil society work on disinformation.</li>
      <li><strong>Proposed deepfake legislation.</strong> Would give citizens copyright over their likeness.</li>
      <li><strong>Act on Supplementary Provisions</strong> (May 2025). Denmark among first EU members implementing AI Act provisions.</li>
      <li><strong>Danish media landscape.</strong> High trust, strong public broadcasting (DR).</li>
    </ul>

    <h2>Guiding Questions</h2>
    <div class="questions">
      <ol>
        <li><strong>Threat assessment:</strong> How serious is the AI disinformation threat to Danish democracy? The Munich Security Conference found "negligible impact" in 2024 elections. Is this reassuring, or are we underestimating future risks?</li>
        <li><strong>Technical solutions:</strong> Csernatoni discusses watermarking and content provenance. How effective are these technical approaches? What are their limitations? Should Denmark mandate them?</li>
        <li><strong>Platform governance:</strong> The AlgorithmWatch piece argues recommendation algorithms are a bigger threat than deepfakes. How should Denmark regulate platforms' algorithmic amplification of content?</li>
        <li><strong>Danish resilience:</strong> Denmark has high media trust and strong public broadcasting. Does this make Denmark more resilient to AI disinformation, or could these strengths be undermined?</li>
        <li><strong>Freedom vs. safety:</strong> Regulating AI-generated content raises free expression concerns. How should Denmark balance protecting democratic discourse with preserving speech freedoms?</li>
      </ol>
    </div>

    <h2>Presentation Angle Ideas</h2>
    <div class="angles">
      <ol>
        <li><strong>"Denmark's AI Democracy Defense":</strong> Propose a comprehensive strategy combining technical standards (watermarking/provenance), platform regulation, and digital literacy initiatives tailored to Danish context.</li>
        <li><strong>"Beyond Deepfake Panic":</strong> Challenge the focus on AI-generated content. Argue that Denmark should prioritize platform governance and algorithmic transparency over content authenticity verification.</li>
        <li><strong>"The Digital Democracy Initiative 2.0":</strong> Evaluate the current initiative (2023–2026) and propose what should come next. What has worked? What gaps remain? What should the next phase prioritize?</li>
        <li><strong>"Nordic Cooperation on AI and Democracy":</strong> Propose coordinated Nordic approaches to AI disinformation. How could Denmark, Sweden, Norway, and Finland share resources and best practices?</li>
      </ol>
    </div>

    <footer>
      <a href="index.html" class="back-link">← Back to overview</a>
    </footer>
  </div>
</body>
</html>
