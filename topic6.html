<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Topic 6: Open Source AI and Power</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;1,400&family=DM+Sans:wght@400;500;600&family=Caveat:wght@500&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-dark: #2A2320;
      --bg-warm: #342D29;
      --bg-card: #3D3632;
      --coral: #E8734A;
      --coral-light: #F5A17A;
      --cream: #F5F0EB;
      --text-light: #E8E4E0;
      --text-muted: #9A938D;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'DM Sans', sans-serif;
      background: var(--bg-dark);
      color: var(--text-light);
      line-height: 1.7;
      font-size: 16px;
    }
    body::before {
      content: '';
      position: fixed;
      top: 0; left: 0;
      width: 100%; height: 100%;
      opacity: 0.03;
      pointer-events: none;
      background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 256 256' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noise'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noise)'/%3E%3C/svg%3E");
    }
    .container { max-width: 900px; margin: 0 auto; padding: 3rem 2rem; }
    .back-link {
      display: inline-flex;
      align-items: center;
      gap: 0.5rem;
      color: var(--coral);
      text-decoration: none;
      font-size: 0.9rem;
      margin-bottom: 2rem;
    }
    .back-link:hover { gap: 0.75rem; }
    .topic-header {
      display: flex;
      justify-content: space-between;
      align-items: flex-start;
      margin-bottom: 2rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid rgba(255,255,255,0.08);
    }
    .topic-header h1 {
      font-family: 'Cormorant Garamond', serif;
      font-size: clamp(2rem, 4vw, 2.75rem);
      font-weight: 400;
      color: var(--cream);
      line-height: 1.2;
    }
    .topic-num {
      font-family: 'Cormorant Garamond', serif;
      font-size: 4rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.25;
      line-height: 1;
    }
    h2 {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.5rem;
      font-weight: 400;
      color: var(--cream);
      margin: 2.5rem 0 1rem;
    }
    h3 {
      font-size: 0.95rem;
      font-weight: 600;
      color: var(--cream);
      margin: 1.5rem 0 0.75rem;
    }
    p { color: var(--text-muted); margin-bottom: 0.75rem; }
    strong { color: var(--text-light); }
    a { color: var(--coral-light); }
    a:hover { text-decoration: none; }
    ul, ol { color: var(--text-muted); margin: 1rem 0; padding-left: 1.25rem; }
    li { margin-bottom: 0.5rem; }
    .reading-box {
      background: var(--bg-warm);
      border-left: 4px solid var(--coral);
      border-radius: 4px;
      padding: 1.5rem;
      margin: 1.5rem 0;
    }
    .reading-box h4 {
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.35rem;
      color: var(--cream);
      margin-bottom: 0.75rem;
    }
    .reading-box p { margin: 0.25rem 0; font-size: 0.95rem; }
    .questions ol { counter-reset: q; list-style: none; padding: 0; }
    .questions li {
      counter-increment: q;
      padding: 0.75rem 0 0.75rem 2.5rem;
      position: relative;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    .questions li::before {
      content: counter(q);
      position: absolute;
      left: 0;
      font-family: 'Cormorant Garamond', serif;
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--coral);
      opacity: 0.6;
    }
    .angles ol { counter-reset: a; list-style: none; padding: 0; }
    .angles li {
      counter-increment: a;
      padding: 0.75rem 0;
      border-bottom: 1px solid rgba(255,255,255,0.05);
    }
    footer {
      margin-top: 3rem;
      padding-top: 2rem;
      border-top: 1px solid rgba(255,255,255,0.08);
    }
    @media (max-width: 600px) {
      .topic-header { flex-direction: column-reverse; gap: 1rem; }
      .topic-num { font-size: 3rem; }
    }
  </style>
</head>
<body>
  <div class="container">
    <a href="index.html" class="back-link">← Back to overview</a>

    <header class="topic-header">
      <h1>Open Source AI and Power</h1>
      <span class="topic-num">06</span>
    </header>

    <p>This topic critically examines claims that "open source" AI democratizes access and distributes power. Widder, West, and Whittaker argue that the terms "open" and "open source" in AI are used inconsistently, often more marketing than technical descriptor. Even maximally open AI systems don't ensure democratic access due to three bottlenecks: compute concentration, data curation costs, and corporate capture of "openness."</p>

    <p><strong>Why this matters for Danish AI policy:</strong> Denmark's public sector is increasingly adopting AI systems. Should procurement favor "open source" AI? Does openness actually deliver the benefits claimed? How should Denmark evaluate DeepSeek and similar "open" models from geopolitical competitors?</p>

    <h2>Required Reading</h2>
    <div class="reading-box">
      <h4>Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI</h4>
      <p><strong>Authors:</strong> David Gray Widder, Sarah West, and Meredith Whittaker</p>
      <p><strong>Publication:</strong> SSRN (accepted to appear in <em>Nature</em>), August 2023</p>
      <p><strong>Length:</strong> ~8,000 words</p>
      <p><strong>URL:</strong> <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4543807">papers.ssrn.com/abstract_id=4543807</a></p>
    </div>

    <h3>Author Credentials</h3>
    <p><strong>Meredith Whittaker</strong> is President of Signal Foundation. She co-founded the AI Now Institute at NYU and served as Senior Advisor to FTC Chair Lina Khan. She is one of the most prominent critics of Big Tech AI concentration.</p>
    <p><strong>David Gray Widder</strong> is a researcher at Carnegie Mellon University focusing on responsible AI.</p>
    <p><strong>Sarah West</strong> is a researcher at the AI Now Institute specializing in AI governance.</p>

    <h2>Supplementary Materials</h2>

    <h3>Podcasts &amp; Videos</h3>
    <ul>
      <li><a href="https://www.msnbc.com/msnbc-podcast/why-is-this-happening/unpacking-moment-tech-meredith-whittaker-podcast-transcript-rcna150104">MSNBC "Why Is This Happening?" with Meredith Whittaker</a> (~50 min; first 25 min ideal). Discussion of AI concentration and the limits of openness. Also on <a href="https://podcasts.apple.com/us/podcast/this-moment-in-tech-with-meredith-whittaker/id1382983397?i=1000653302953">Apple Podcasts</a>.</li>
      <li>AI Now Salons "What is AI?" series. Broader context on AI power dynamics.</li>
    </ul>

    <h3>DeepSeek and Current Debates (Updated Feb 2026)</h3>
    <ul>
      <li><strong>Government bans:</strong> Australia and Czech Republic banned DeepSeek from government devices (Jan/Feb 2026) over data security concerns. DeepSeek stores personal data on servers in China.</li>
      <li><strong>US Congressional concerns:</strong> <a href="https://chinaselectcommittee.house.gov/sites/evo-subsites/selectcommitteeontheccp.house.gov/files/evo-media-document/letter-to-doc-nvidia-deepseek-pla-use_final.pdf">Letter to Commerce Department</a> (Jan 2026) raised concerns about NVIDIA support enabling DeepSeek capabilities now integrated into PLA systems.</li>
      <li><a href="https://www.lawfaremedia.org/article/what-deepseek-r1-means-and-what-it-doesn-t">Lawfare: What DeepSeek R1 Means—and What It Doesn't</a>. Analysis of export control implications.</li>
      <li>Stanford HAI: "How Disruptive is DeepSeek?" (February 2025). Faculty roundtable on R1's implications.</li>
    </ul>

    <h3>Additional Context</h3>
    <ul>
      <li>Carnegie Endowment: "Beyond Open vs. Closed" (July 2024, ~7,500 words). Multi-stakeholder consensus identifying 7 areas of agreement and 17 open questions.</li>
      <li>Open Source Initiative: "Meta's LLaMa License is Still Not Open Source" (October 2024). Documents Llama's failure to meet Open Source Definition.</li>
    </ul>

    <h3>Danish Context</h3>
    <ul>
      <li>Danish public sector AI procurement guidelines</li>
      <li>EU AI Act requirements for foundation models</li>
      <li>Danish Data Protection Agency guidance on AI systems</li>
    </ul>

    <h2>Guiding Questions</h2>
    <div class="questions">
      <ol>
        <li><strong>Defining "open":</strong> The authors argue "open" is used inconsistently in AI. What are the different meanings of openness (open weights, open data, open training code, open governance)? Which matter most for the benefits claimed?</li>
        <li><strong>The three bottlenecks:</strong> Compute concentration, data curation costs, and corporate capture are identified as barriers. Which is most significant? Can any be addressed through policy?</li>
        <li><strong>DeepSeek puzzle:</strong> China's DeepSeek released powerful "open" models. How does this complicate the analysis? Should Denmark treat DeepSeek differently than Meta's Llama or Mistral's models?</li>
        <li><strong>Procurement policy:</strong> Should Danish public sector procurement favor "open source" AI? What criteria should determine this? How should procurement weigh openness against other factors (security, performance, support)?</li>
        <li><strong>Democratization claims:</strong> The authors are skeptical that openness democratizes AI. Under what conditions, if any, could openness genuinely distribute power? What complementary policies would be needed?</li>
      </ol>
    </div>

    <h2>Presentation Angle Ideas</h2>
    <div class="angles">
      <ol>
        <li><strong>"Procurement Guidelines for 'Open' AI":</strong> Develop specific criteria Denmark should use when evaluating "open source" AI for public sector use. What counts as genuinely open? What red flags should trigger skepticism?</li>
        <li><strong>"The DeepSeek Dilemma":</strong> Focus on the specific challenge posed by capable open models from geopolitical competitors. How should Denmark balance the benefits of open access against security and sovereignty concerns?</li>
        <li><strong>"Beyond Open vs. Closed":</strong> Argue that the open/closed binary is unhelpful. Propose a more nuanced framework for evaluating AI systems that accounts for governance, accountability, and actual accessibility.</li>
        <li><strong>"Making Openness Work":</strong> Accept the authors' critique but propose complementary policies that could make openness deliver on its promises. What public investments, governance structures, or regulations would help?</li>
      </ol>
    </div>

    <footer>
      <a href="index.html" class="back-link">← Back to overview</a>
    </footer>
  </div>
</body>
</html>
